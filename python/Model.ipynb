{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb8be1f-157c-4797-84b1-c14d534c06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcdb7a6-e5c2-4995-801a-ca95d8a0bb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>0.160953</td>\n",
       "      <td>0.300626</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>6.144175e-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438677</td>\n",
       "      <td>0.674675</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.199005</td>\n",
       "      <td>0.342808</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>3.775135e-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.561323</td>\n",
       "      <td>0.349349</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.160953</td>\n",
       "      <td>0.342808</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>2.248168e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.438677</td>\n",
       "      <td>0.449449</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.172344</td>\n",
       "      <td>0.266167</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.561323</td>\n",
       "      <td>0.949950</td>\n",
       "      <td>0.800992</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>0.172344</td>\n",
       "      <td>0.200615</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.438677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.160953</td>\n",
       "      <td>0.342808</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>2.789468e-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.438677</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.160953</td>\n",
       "      <td>0.145758</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.561323</td>\n",
       "      <td>0.824825</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.287018</td>\n",
       "      <td>0.352908</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.438677</td>\n",
       "      <td>0.299299</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.160953</td>\n",
       "      <td>0.503221</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.061154e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.438677</td>\n",
       "      <td>0.712212</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>0.172344</td>\n",
       "      <td>0.245966</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>2.789468e-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gender       age  hypertension  heart_disease  smoking_history  \\\n",
       "0      0.438677  1.000000      0.199008       0.810193         0.160953   \n",
       "1      0.438677  0.674675      0.199008       0.189807         0.199005   \n",
       "2      0.561323  0.349349      0.199008       0.189807         0.160953   \n",
       "3      0.438677  0.449449      0.199008       0.189807         0.172344   \n",
       "4      0.561323  0.949950      0.800992       0.810193         0.172344   \n",
       "...         ...       ...           ...            ...              ...   \n",
       "99995  0.438677  1.000000      0.199008       0.189807         0.160953   \n",
       "99996  0.438677  0.024024      0.199008       0.189807         0.160953   \n",
       "99997  0.561323  0.824825      0.199008       0.189807         0.287018   \n",
       "99998  0.438677  0.299299      0.199008       0.189807         0.160953   \n",
       "99999  0.438677  0.712212      0.199008       0.189807         0.172344   \n",
       "\n",
       "            bmi  HbA1c_level  blood_glucose_level  diabetes  \n",
       "0      0.300626     0.622459         6.144175e-06         0  \n",
       "1      0.342808     0.622459         3.775135e-11         0  \n",
       "2      0.342808     0.017986         2.248168e-04         0  \n",
       "3      0.266167     0.000553         1.233946e-04         0  \n",
       "4      0.200615     0.000203         1.233946e-04         0  \n",
       "...         ...          ...                  ...       ...  \n",
       "99995  0.342808     0.182426         2.789468e-10         0  \n",
       "99996  0.145758     0.500000         2.061154e-09         0  \n",
       "99997  0.352908     0.017986         1.233946e-04         0  \n",
       "99998  0.503221     0.000004         2.061154e-09         0  \n",
       "99999  0.245966     0.622459         2.789468e-10         0  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/diabetes_prediction_dataset_preprocessed.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492b4e1-9ac4-443b-9b13-a9928e2889ed",
   "metadata": {},
   "source": [
    "## GPU를 사용할 수 있다면 사용 가능하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce260fd-5b36-4ef7-8e5d-0511adccb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a81ee5b-0628-403a-8c85-5a52021b95ce",
   "metadata": {},
   "source": [
    "## Pytorch가 사용할 수 있도록 tensor로 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c6a91d-e02b-4b32-8ef9-322e2f2d201c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.38676740e-01, 1.00000000e+00, 1.99008115e-01, ...,\n",
       "        6.22459331e-01, 6.14417460e-06, 0.00000000e+00],\n",
       "       [4.38676740e-01, 6.74674675e-01, 1.99008115e-01, ...,\n",
       "        6.22459331e-01, 3.77513454e-11, 0.00000000e+00],\n",
       "       [5.61323260e-01, 3.49349349e-01, 1.99008115e-01, ...,\n",
       "        1.79862100e-02, 2.24816770e-04, 0.00000000e+00],\n",
       "       ...,\n",
       "       [5.61323260e-01, 8.24824825e-01, 1.99008115e-01, ...,\n",
       "        1.79862100e-02, 1.23394576e-04, 0.00000000e+00],\n",
       "       [4.38676740e-01, 2.99299299e-01, 1.99008115e-01, ...,\n",
       "        3.72663928e-06, 2.06115362e-09, 0.00000000e+00],\n",
       "       [4.38676740e-01, 7.12212212e-01, 1.99008115e-01, ...,\n",
       "        6.22459331e-01, 2.78946809e-10, 0.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_np = df.to_numpy()\n",
    "df_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e268f8d-e63c-490f-967b-57f9e7325be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3868e-01, 1.0000e+00, 1.9901e-01,  ..., 6.2246e-01, 6.1442e-06,\n",
       "         0.0000e+00],\n",
       "        [4.3868e-01, 6.7467e-01, 1.9901e-01,  ..., 6.2246e-01, 3.7751e-11,\n",
       "         0.0000e+00],\n",
       "        [5.6132e-01, 3.4935e-01, 1.9901e-01,  ..., 1.7986e-02, 2.2482e-04,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [5.6132e-01, 8.2482e-01, 1.9901e-01,  ..., 1.7986e-02, 1.2339e-04,\n",
       "         0.0000e+00],\n",
       "        [4.3868e-01, 2.9930e-01, 1.9901e-01,  ..., 3.7266e-06, 2.0612e-09,\n",
       "         0.0000e+00],\n",
       "        [4.3868e-01, 7.1221e-01, 1.9901e-01,  ..., 6.2246e-01, 2.7895e-10,\n",
       "         0.0000e+00]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tensor = torch.tensor(df_np).to(device)\n",
    "df_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a69a61-26df-4ed3-9fe6-74eddb261322",
   "metadata": {},
   "source": [
    "## trainset, testset으로 나눈다 (4:1 비율로 나누기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a16a978-1f5c-4d94-ad1b-6e450e78963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80000, 9])\n",
      "torch.Size([20000, 9])\n"
     ]
    }
   ],
   "source": [
    "cutting = df_tensor.shape[0] // 5\n",
    "cutting = cutting * 4\n",
    "\n",
    "trainset = df_tensor[:cutting]\n",
    "testset = df_tensor[cutting:]\n",
    "\n",
    "print(trainset.shape)\n",
    "print(testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86961669-9f54-463e-b900-12b15c127f8b",
   "metadata": {},
   "source": [
    "## feature와 target으로 나눈다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd40fa-ad4c-4eb9-8e83-fddd91b0a88a",
   "metadata": {},
   "source": [
    "## 참고로 tensor의 열은 [:,n] 형식으로 접근한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179771db-d9c2-4753-bd20-7910283bc578",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainset = trainset[:, 0:8]\n",
    "x_testset = testset[:, 0:8]\n",
    "\n",
    "y_trainset = trainset[:,8].unsqueeze(dim = 1)\n",
    "y_testset = testset[:,8].unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf83db2-4fca-4fc8-8da2-59fb758c45fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.3868e-01, 1.0000e+00, 1.9901e-01,  ..., 3.0063e-01, 6.2246e-01,\n",
      "         6.1442e-06],\n",
      "        [4.3868e-01, 6.7467e-01, 1.9901e-01,  ..., 3.4281e-01, 6.2246e-01,\n",
      "         3.7751e-11],\n",
      "        [5.6132e-01, 3.4935e-01, 1.9901e-01,  ..., 3.4281e-01, 1.7986e-02,\n",
      "         2.2482e-04],\n",
      "        ...,\n",
      "        [5.6132e-01, 3.2432e-01, 1.9901e-01,  ..., 3.2063e-01, 1.1920e-01,\n",
      "         1.0000e+00],\n",
      "        [4.3868e-01, 5.8709e-01, 8.0099e-01,  ..., 3.2320e-01, 6.2246e-01,\n",
      "         1.0000e+00],\n",
      "        [4.3868e-01, 8.1231e-01, 8.0099e-01,  ..., 5.2540e-01, 2.0343e-04,\n",
      "         2.7458e-04]], device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([80000, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_trainset)\n",
    "x_trainset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db502fc3-e43f-4d29-bf38-115878802f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68c471-63e2-4c69-b9ef-ae68b347d7cc",
   "metadata": {},
   "source": [
    "## traget 텐서를 원-핫 인코딩 형태로 바꾸자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9134372a-a43e-4b59-97c6-c30aa51f4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainset = torch.nn.functional.one_hot(y_trainset.to(torch.int64), num_classes=2)\n",
    "y_testset = torch.nn.functional.one_hot(y_testset.to(torch.int64), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f88dc898-97a7-448f-85fb-170e9fdd3cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0]],\n",
       "\n",
       "        [[1, 0]],\n",
       "\n",
       "        [[1, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 1]],\n",
       "\n",
       "        [[0, 1]],\n",
       "\n",
       "        [[1, 0]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be0f17-d67f-422c-82b4-9766a2970bac",
   "metadata": {},
   "source": [
    "## 모델을 설계하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31fce13d-39dc-4f50-b0ba-4f82e719b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공사중\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, device=device):\n",
    "        super().__init__()\n",
    "        self.continuous_input = nn.Linear(in_features=4, out_features=6, device=device, dtype=torch.float64)\n",
    "        self.discrete_input = nn.Linear(in_features=4, out_features=6, device=device)\n",
    "        self.continuous_hidden = nn.Linear(in_features=6, out_features=1, device=device)\n",
    "        self.discrete_hidden = nn.Linear(in_features=6, out_features=1, device=device)\n",
    "        self.output = nn.Linear(in_features=2, out_features=1, device=device)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # gender age hypertension heart_disease smoking_history bmi HbA1c_level blood_glucose_level diabetes\n",
    "        x_continuous = x[[1, 5, 6, 7]]\n",
    "        x_discrete = x[[0, 2, 3, 4]]\n",
    "\n",
    "        out1 = self.continuous_input(x_continuous)\n",
    "        out2 = self.discrete_input(x_discrete)\n",
    "        out1 = self.continuous_hidden(out1)\n",
    "        out2 = self.discrete_hidden(out2)\n",
    "\n",
    "        out = output([out1, out2])\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "model = FullyConnected().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161da6c2-16d7-4c90-9a24-c12646d5b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected2(nn.Module):\n",
    "    def __init__(self, device=device):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_features=8, out_features=12, device=device, dtype=torch.float64)\n",
    "        self.hidden = nn.Linear(in_features=12, out_features=6, device=device, dtype=torch.float64)\n",
    "        self.output = nn.Linear(in_features=6, out_features=2, device=device, dtype=torch.float64)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.input(x)\n",
    "        out = self.hidden(out)\n",
    "        out = self.output(out)\n",
    "        out = self.softmax(out)\n",
    "        return out # [100, 2]\n",
    "\n",
    "model = FullyConnected().to(device)\n",
    "model2 = FullyConnected2().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487a0f6-ed14-4a9c-b0a7-ad9e9d4cf22d",
   "metadata": {},
   "source": [
    "## DataLoader, learning rate, optimizer, criterion을 정의하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a288176-c09d-4f3a-a1d5-495d782f924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataset.TensorDataset'>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x0000018D73192C40>\n"
     ]
    }
   ],
   "source": [
    "trainset = TensorDataset(x_trainset, y_trainset)\n",
    "print(type(trainset))\n",
    "print(trainset)\n",
    "\n",
    "trainbatchsize = 100\n",
    "trainloader = DataLoader(trainset, batch_size = trainbatchsize, shuffle = True)\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=lr)\n",
    "\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43cee1c-2ba9-4dab-9ce2-6cc12ff945e3",
   "metadata": {},
   "source": [
    "## 실제로 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "705150e1-ee3b-4d17-8b9c-77ea3d372d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\embed\\anaconda3\\envs\\torch_book\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 0.211\n",
      "1th epoch and 100th batchcount\n",
      "[1, 200] loss: 0.141\n",
      "1th epoch and 200th batchcount\n",
      "[1, 300] loss: 0.139\n",
      "1th epoch and 300th batchcount\n",
      "[1, 400] loss: 0.148\n",
      "1th epoch and 400th batchcount\n",
      "[1, 500] loss: 0.136\n",
      "1th epoch and 500th batchcount\n",
      "[1, 600] loss: 0.129\n",
      "1th epoch and 600th batchcount\n",
      "[1, 700] loss: 0.133\n",
      "1th epoch and 700th batchcount\n",
      "[1, 800] loss: 0.142\n",
      "1th epoch and 800th batchcount\n",
      "[2, 100] loss: 0.136\n",
      "2th epoch and 100th batchcount\n",
      "[2, 200] loss: 0.137\n",
      "2th epoch and 200th batchcount\n",
      "[2, 300] loss: 0.133\n",
      "2th epoch and 300th batchcount\n",
      "[2, 400] loss: 0.135\n",
      "2th epoch and 400th batchcount\n",
      "[2, 500] loss: 0.141\n",
      "2th epoch and 500th batchcount\n",
      "[2, 600] loss: 0.143\n",
      "2th epoch and 600th batchcount\n",
      "[2, 700] loss: 0.137\n",
      "2th epoch and 700th batchcount\n",
      "[2, 800] loss: 0.137\n",
      "2th epoch and 800th batchcount\n",
      "[3, 100] loss: 0.136\n",
      "3th epoch and 100th batchcount\n",
      "[3, 200] loss: 0.140\n",
      "3th epoch and 200th batchcount\n",
      "[3, 300] loss: 0.134\n",
      "3th epoch and 300th batchcount\n",
      "[3, 400] loss: 0.131\n",
      "3th epoch and 400th batchcount\n",
      "[3, 500] loss: 0.139\n",
      "3th epoch and 500th batchcount\n",
      "[3, 600] loss: 0.138\n",
      "3th epoch and 600th batchcount\n",
      "[3, 700] loss: 0.138\n",
      "3th epoch and 700th batchcount\n",
      "[3, 800] loss: 0.143\n",
      "3th epoch and 800th batchcount\n",
      "[4, 100] loss: 0.133\n",
      "4th epoch and 100th batchcount\n",
      "[4, 200] loss: 0.138\n",
      "4th epoch and 200th batchcount\n",
      "[4, 300] loss: 0.143\n",
      "4th epoch and 300th batchcount\n",
      "[4, 400] loss: 0.147\n",
      "4th epoch and 400th batchcount\n",
      "[4, 500] loss: 0.130\n",
      "4th epoch and 500th batchcount\n",
      "[4, 600] loss: 0.137\n",
      "4th epoch and 600th batchcount\n",
      "[4, 700] loss: 0.131\n",
      "4th epoch and 700th batchcount\n",
      "[4, 800] loss: 0.138\n",
      "4th epoch and 800th batchcount\n",
      "[5, 100] loss: 0.141\n",
      "5th epoch and 100th batchcount\n",
      "[5, 200] loss: 0.142\n",
      "5th epoch and 200th batchcount\n",
      "[5, 300] loss: 0.139\n",
      "5th epoch and 300th batchcount\n",
      "[5, 400] loss: 0.139\n",
      "5th epoch and 400th batchcount\n",
      "[5, 500] loss: 0.142\n",
      "5th epoch and 500th batchcount\n",
      "[5, 600] loss: 0.134\n",
      "5th epoch and 600th batchcount\n",
      "[5, 700] loss: 0.131\n",
      "5th epoch and 700th batchcount\n",
      "[5, 800] loss: 0.130\n",
      "5th epoch and 800th batchcount\n",
      "[6, 100] loss: 0.144\n",
      "6th epoch and 100th batchcount\n",
      "[6, 200] loss: 0.138\n",
      "6th epoch and 200th batchcount\n",
      "[6, 300] loss: 0.130\n",
      "6th epoch and 300th batchcount\n",
      "[6, 400] loss: 0.138\n",
      "6th epoch and 400th batchcount\n",
      "[6, 500] loss: 0.139\n",
      "6th epoch and 500th batchcount\n",
      "[6, 600] loss: 0.135\n",
      "6th epoch and 600th batchcount\n",
      "[6, 700] loss: 0.139\n",
      "6th epoch and 700th batchcount\n",
      "[6, 800] loss: 0.130\n",
      "6th epoch and 800th batchcount\n",
      "[7, 100] loss: 0.137\n",
      "7th epoch and 100th batchcount\n",
      "[7, 200] loss: 0.132\n",
      "7th epoch and 200th batchcount\n",
      "[7, 300] loss: 0.141\n",
      "7th epoch and 300th batchcount\n",
      "[7, 400] loss: 0.144\n",
      "7th epoch and 400th batchcount\n",
      "[7, 500] loss: 0.129\n",
      "7th epoch and 500th batchcount\n",
      "[7, 600] loss: 0.135\n",
      "7th epoch and 600th batchcount\n",
      "[7, 700] loss: 0.141\n",
      "7th epoch and 700th batchcount\n",
      "[7, 800] loss: 0.136\n",
      "7th epoch and 800th batchcount\n",
      "[8, 100] loss: 0.141\n",
      "8th epoch and 100th batchcount\n",
      "[8, 200] loss: 0.137\n",
      "8th epoch and 200th batchcount\n",
      "[8, 300] loss: 0.139\n",
      "8th epoch and 300th batchcount\n",
      "[8, 400] loss: 0.134\n",
      "8th epoch and 400th batchcount\n",
      "[8, 500] loss: 0.134\n",
      "8th epoch and 500th batchcount\n",
      "[8, 600] loss: 0.137\n",
      "8th epoch and 600th batchcount\n",
      "[8, 700] loss: 0.127\n",
      "8th epoch and 700th batchcount\n",
      "[8, 800] loss: 0.141\n",
      "8th epoch and 800th batchcount\n",
      "[9, 100] loss: 0.138\n",
      "9th epoch and 100th batchcount\n",
      "[9, 200] loss: 0.135\n",
      "9th epoch and 200th batchcount\n",
      "[9, 300] loss: 0.135\n",
      "9th epoch and 300th batchcount\n",
      "[9, 400] loss: 0.141\n",
      "9th epoch and 400th batchcount\n",
      "[9, 500] loss: 0.133\n",
      "9th epoch and 500th batchcount\n",
      "[9, 600] loss: 0.147\n",
      "9th epoch and 600th batchcount\n",
      "[9, 700] loss: 0.131\n",
      "9th epoch and 700th batchcount\n",
      "[9, 800] loss: 0.133\n",
      "9th epoch and 800th batchcount\n",
      "[10, 100] loss: 0.127\n",
      "10th epoch and 100th batchcount\n",
      "[10, 200] loss: 0.136\n",
      "10th epoch and 200th batchcount\n",
      "[10, 300] loss: 0.146\n",
      "10th epoch and 300th batchcount\n",
      "[10, 400] loss: 0.139\n",
      "10th epoch and 400th batchcount\n",
      "[10, 500] loss: 0.135\n",
      "10th epoch and 500th batchcount\n",
      "[10, 600] loss: 0.138\n",
      "10th epoch and 600th batchcount\n",
      "[10, 700] loss: 0.135\n",
      "10th epoch and 700th batchcount\n",
      "[10, 800] loss: 0.137\n",
      "10th epoch and 800th batchcount\n",
      "[11, 100] loss: 0.131\n",
      "11th epoch and 100th batchcount\n",
      "[11, 200] loss: 0.145\n",
      "11th epoch and 200th batchcount\n",
      "[11, 300] loss: 0.139\n",
      "11th epoch and 300th batchcount\n",
      "[11, 400] loss: 0.137\n",
      "11th epoch and 400th batchcount\n",
      "[11, 500] loss: 0.130\n",
      "11th epoch and 500th batchcount\n",
      "[11, 600] loss: 0.141\n",
      "11th epoch and 600th batchcount\n",
      "[11, 700] loss: 0.136\n",
      "11th epoch and 700th batchcount\n",
      "[11, 800] loss: 0.131\n",
      "11th epoch and 800th batchcount\n",
      "[12, 100] loss: 0.130\n",
      "12th epoch and 100th batchcount\n",
      "[12, 200] loss: 0.139\n",
      "12th epoch and 200th batchcount\n",
      "[12, 300] loss: 0.127\n",
      "12th epoch and 300th batchcount\n",
      "[12, 400] loss: 0.141\n",
      "12th epoch and 400th batchcount\n",
      "[12, 500] loss: 0.130\n",
      "12th epoch and 500th batchcount\n",
      "[12, 600] loss: 0.131\n",
      "12th epoch and 600th batchcount\n",
      "[12, 700] loss: 0.146\n",
      "12th epoch and 700th batchcount\n",
      "[12, 800] loss: 0.147\n",
      "12th epoch and 800th batchcount\n",
      "[13, 100] loss: 0.127\n",
      "13th epoch and 100th batchcount\n",
      "[13, 200] loss: 0.131\n",
      "13th epoch and 200th batchcount\n",
      "[13, 300] loss: 0.131\n",
      "13th epoch and 300th batchcount\n",
      "[13, 400] loss: 0.139\n",
      "13th epoch and 400th batchcount\n",
      "[13, 500] loss: 0.136\n",
      "13th epoch and 500th batchcount\n",
      "[13, 600] loss: 0.144\n",
      "13th epoch and 600th batchcount\n",
      "[13, 700] loss: 0.137\n",
      "13th epoch and 700th batchcount\n",
      "[13, 800] loss: 0.145\n",
      "13th epoch and 800th batchcount\n",
      "[14, 100] loss: 0.138\n",
      "14th epoch and 100th batchcount\n",
      "[14, 200] loss: 0.131\n",
      "14th epoch and 200th batchcount\n",
      "[14, 300] loss: 0.132\n",
      "14th epoch and 300th batchcount\n",
      "[14, 400] loss: 0.134\n",
      "14th epoch and 400th batchcount\n",
      "[14, 500] loss: 0.139\n",
      "14th epoch and 500th batchcount\n",
      "[14, 600] loss: 0.133\n",
      "14th epoch and 600th batchcount\n",
      "[14, 700] loss: 0.144\n",
      "14th epoch and 700th batchcount\n",
      "[14, 800] loss: 0.138\n",
      "14th epoch and 800th batchcount\n",
      "[15, 100] loss: 0.142\n",
      "15th epoch and 100th batchcount\n",
      "[15, 200] loss: 0.129\n",
      "15th epoch and 200th batchcount\n",
      "[15, 300] loss: 0.134\n",
      "15th epoch and 300th batchcount\n",
      "[15, 400] loss: 0.138\n",
      "15th epoch and 400th batchcount\n",
      "[15, 500] loss: 0.142\n",
      "15th epoch and 500th batchcount\n",
      "[15, 600] loss: 0.127\n",
      "15th epoch and 600th batchcount\n",
      "[15, 700] loss: 0.131\n",
      "15th epoch and 700th batchcount\n",
      "[15, 800] loss: 0.148\n",
      "15th epoch and 800th batchcount\n",
      "[16, 100] loss: 0.128\n",
      "16th epoch and 100th batchcount\n",
      "[16, 200] loss: 0.136\n",
      "16th epoch and 200th batchcount\n",
      "[16, 300] loss: 0.140\n",
      "16th epoch and 300th batchcount\n",
      "[16, 400] loss: 0.142\n",
      "16th epoch and 400th batchcount\n",
      "[16, 500] loss: 0.131\n",
      "16th epoch and 500th batchcount\n",
      "[16, 600] loss: 0.133\n",
      "16th epoch and 600th batchcount\n",
      "[16, 700] loss: 0.143\n",
      "16th epoch and 700th batchcount\n",
      "[16, 800] loss: 0.135\n",
      "16th epoch and 800th batchcount\n",
      "[17, 100] loss: 0.134\n",
      "17th epoch and 100th batchcount\n",
      "[17, 200] loss: 0.137\n",
      "17th epoch and 200th batchcount\n",
      "[17, 300] loss: 0.146\n",
      "17th epoch and 300th batchcount\n",
      "[17, 400] loss: 0.135\n",
      "17th epoch and 400th batchcount\n",
      "[17, 500] loss: 0.127\n",
      "17th epoch and 500th batchcount\n",
      "[17, 600] loss: 0.137\n",
      "17th epoch and 600th batchcount\n",
      "[17, 700] loss: 0.134\n",
      "17th epoch and 700th batchcount\n",
      "[17, 800] loss: 0.137\n",
      "17th epoch and 800th batchcount\n",
      "[18, 100] loss: 0.138\n",
      "18th epoch and 100th batchcount\n",
      "[18, 200] loss: 0.143\n",
      "18th epoch and 200th batchcount\n",
      "[18, 300] loss: 0.141\n",
      "18th epoch and 300th batchcount\n",
      "[18, 400] loss: 0.137\n",
      "18th epoch and 400th batchcount\n",
      "[18, 500] loss: 0.134\n",
      "18th epoch and 500th batchcount\n",
      "[18, 600] loss: 0.121\n",
      "18th epoch and 600th batchcount\n",
      "[18, 700] loss: 0.139\n",
      "18th epoch and 700th batchcount\n",
      "[18, 800] loss: 0.133\n",
      "18th epoch and 800th batchcount\n",
      "[19, 100] loss: 0.125\n",
      "19th epoch and 100th batchcount\n",
      "[19, 200] loss: 0.135\n",
      "19th epoch and 200th batchcount\n",
      "[19, 300] loss: 0.131\n",
      "19th epoch and 300th batchcount\n",
      "[19, 400] loss: 0.140\n",
      "19th epoch and 400th batchcount\n",
      "[19, 500] loss: 0.145\n",
      "19th epoch and 500th batchcount\n",
      "[19, 600] loss: 0.143\n",
      "19th epoch and 600th batchcount\n",
      "[19, 700] loss: 0.135\n",
      "19th epoch and 700th batchcount\n",
      "[19, 800] loss: 0.134\n",
      "19th epoch and 800th batchcount\n",
      "[20, 100] loss: 0.132\n",
      "20th epoch and 100th batchcount\n",
      "[20, 200] loss: 0.140\n",
      "20th epoch and 200th batchcount\n",
      "[20, 300] loss: 0.137\n",
      "20th epoch and 300th batchcount\n",
      "[20, 400] loss: 0.138\n",
      "20th epoch and 400th batchcount\n",
      "[20, 500] loss: 0.141\n",
      "20th epoch and 500th batchcount\n",
      "[20, 600] loss: 0.141\n",
      "20th epoch and 600th batchcount\n",
      "[20, 700] loss: 0.127\n",
      "20th epoch and 700th batchcount\n",
      "[20, 800] loss: 0.132\n",
      "20th epoch and 800th batchcount\n",
      "[21, 100] loss: 0.134\n",
      "21th epoch and 100th batchcount\n",
      "[21, 200] loss: 0.144\n",
      "21th epoch and 200th batchcount\n",
      "[21, 300] loss: 0.130\n",
      "21th epoch and 300th batchcount\n",
      "[21, 400] loss: 0.138\n",
      "21th epoch and 400th batchcount\n",
      "[21, 500] loss: 0.129\n",
      "21th epoch and 500th batchcount\n",
      "[21, 600] loss: 0.135\n",
      "21th epoch and 600th batchcount\n",
      "[21, 700] loss: 0.141\n",
      "21th epoch and 700th batchcount\n",
      "[21, 800] loss: 0.137\n",
      "21th epoch and 800th batchcount\n",
      "[22, 100] loss: 0.134\n",
      "22th epoch and 100th batchcount\n",
      "[22, 200] loss: 0.133\n",
      "22th epoch and 200th batchcount\n",
      "[22, 300] loss: 0.131\n",
      "22th epoch and 300th batchcount\n",
      "[22, 400] loss: 0.132\n",
      "22th epoch and 400th batchcount\n",
      "[22, 500] loss: 0.141\n",
      "22th epoch and 500th batchcount\n",
      "[22, 600] loss: 0.142\n",
      "22th epoch and 600th batchcount\n",
      "[22, 700] loss: 0.136\n",
      "22th epoch and 700th batchcount\n",
      "[22, 800] loss: 0.137\n",
      "22th epoch and 800th batchcount\n",
      "[23, 100] loss: 0.128\n",
      "23th epoch and 100th batchcount\n",
      "[23, 200] loss: 0.135\n",
      "23th epoch and 200th batchcount\n",
      "[23, 300] loss: 0.142\n",
      "23th epoch and 300th batchcount\n",
      "[23, 400] loss: 0.130\n",
      "23th epoch and 400th batchcount\n",
      "[23, 500] loss: 0.144\n",
      "23th epoch and 500th batchcount\n",
      "[23, 600] loss: 0.134\n",
      "23th epoch and 600th batchcount\n",
      "[23, 700] loss: 0.136\n",
      "23th epoch and 700th batchcount\n",
      "[23, 800] loss: 0.138\n",
      "23th epoch and 800th batchcount\n",
      "[24, 100] loss: 0.143\n",
      "24th epoch and 100th batchcount\n",
      "[24, 200] loss: 0.144\n",
      "24th epoch and 200th batchcount\n",
      "[24, 300] loss: 0.141\n",
      "24th epoch and 300th batchcount\n",
      "[24, 400] loss: 0.131\n",
      "24th epoch and 400th batchcount\n",
      "[24, 500] loss: 0.125\n",
      "24th epoch and 500th batchcount\n",
      "[24, 600] loss: 0.126\n",
      "24th epoch and 600th batchcount\n",
      "[24, 700] loss: 0.138\n",
      "24th epoch and 700th batchcount\n",
      "[24, 800] loss: 0.140\n",
      "24th epoch and 800th batchcount\n",
      "[25, 100] loss: 0.131\n",
      "25th epoch and 100th batchcount\n",
      "[25, 200] loss: 0.136\n",
      "25th epoch and 200th batchcount\n",
      "[25, 300] loss: 0.144\n",
      "25th epoch and 300th batchcount\n",
      "[25, 400] loss: 0.138\n",
      "25th epoch and 400th batchcount\n",
      "[25, 500] loss: 0.135\n",
      "25th epoch and 500th batchcount\n",
      "[25, 600] loss: 0.135\n",
      "25th epoch and 600th batchcount\n",
      "[25, 700] loss: 0.132\n",
      "25th epoch and 700th batchcount\n",
      "[25, 800] loss: 0.136\n",
      "25th epoch and 800th batchcount\n",
      "[26, 100] loss: 0.139\n",
      "26th epoch and 100th batchcount\n",
      "[26, 200] loss: 0.141\n",
      "26th epoch and 200th batchcount\n",
      "[26, 300] loss: 0.136\n",
      "26th epoch and 300th batchcount\n",
      "[26, 400] loss: 0.138\n",
      "26th epoch and 400th batchcount\n",
      "[26, 500] loss: 0.138\n",
      "26th epoch and 500th batchcount\n",
      "[26, 600] loss: 0.129\n",
      "26th epoch and 600th batchcount\n",
      "[26, 700] loss: 0.133\n",
      "26th epoch and 700th batchcount\n",
      "[26, 800] loss: 0.134\n",
      "26th epoch and 800th batchcount\n",
      "[27, 100] loss: 0.141\n",
      "27th epoch and 100th batchcount\n",
      "[27, 200] loss: 0.131\n",
      "27th epoch and 200th batchcount\n",
      "[27, 300] loss: 0.141\n",
      "27th epoch and 300th batchcount\n",
      "[27, 400] loss: 0.137\n",
      "27th epoch and 400th batchcount\n",
      "[27, 500] loss: 0.130\n",
      "27th epoch and 500th batchcount\n",
      "[27, 600] loss: 0.138\n",
      "27th epoch and 600th batchcount\n",
      "[27, 700] loss: 0.130\n",
      "27th epoch and 700th batchcount\n",
      "[27, 800] loss: 0.139\n",
      "27th epoch and 800th batchcount\n",
      "[28, 100] loss: 0.131\n",
      "28th epoch and 100th batchcount\n",
      "[28, 200] loss: 0.137\n",
      "28th epoch and 200th batchcount\n",
      "[28, 300] loss: 0.150\n",
      "28th epoch and 300th batchcount\n",
      "[28, 400] loss: 0.137\n",
      "28th epoch and 400th batchcount\n",
      "[28, 500] loss: 0.130\n",
      "28th epoch and 500th batchcount\n",
      "[28, 600] loss: 0.138\n",
      "28th epoch and 600th batchcount\n",
      "[28, 700] loss: 0.134\n",
      "28th epoch and 700th batchcount\n",
      "[28, 800] loss: 0.128\n",
      "28th epoch and 800th batchcount\n",
      "[29, 100] loss: 0.135\n",
      "29th epoch and 100th batchcount\n",
      "[29, 200] loss: 0.137\n",
      "29th epoch and 200th batchcount\n",
      "[29, 300] loss: 0.136\n",
      "29th epoch and 300th batchcount\n",
      "[29, 400] loss: 0.142\n",
      "29th epoch and 400th batchcount\n",
      "[29, 500] loss: 0.132\n",
      "29th epoch and 500th batchcount\n",
      "[29, 600] loss: 0.134\n",
      "29th epoch and 600th batchcount\n",
      "[29, 700] loss: 0.141\n",
      "29th epoch and 700th batchcount\n",
      "[29, 800] loss: 0.128\n",
      "29th epoch and 800th batchcount\n",
      "[30, 100] loss: 0.152\n",
      "30th epoch and 100th batchcount\n",
      "[30, 200] loss: 0.132\n",
      "30th epoch and 200th batchcount\n",
      "[30, 300] loss: 0.136\n",
      "30th epoch and 300th batchcount\n",
      "[30, 400] loss: 0.138\n",
      "30th epoch and 400th batchcount\n",
      "[30, 500] loss: 0.138\n",
      "30th epoch and 500th batchcount\n",
      "[30, 600] loss: 0.127\n",
      "30th epoch and 600th batchcount\n",
      "[30, 700] loss: 0.134\n",
      "30th epoch and 700th batchcount\n",
      "[30, 800] loss: 0.130\n",
      "30th epoch and 800th batchcount\n",
      "[31, 100] loss: 0.130\n",
      "31th epoch and 100th batchcount\n",
      "[31, 200] loss: 0.132\n",
      "31th epoch and 200th batchcount\n",
      "[31, 300] loss: 0.142\n",
      "31th epoch and 300th batchcount\n",
      "[31, 400] loss: 0.132\n",
      "31th epoch and 400th batchcount\n",
      "[31, 500] loss: 0.132\n",
      "31th epoch and 500th batchcount\n",
      "[31, 600] loss: 0.136\n",
      "31th epoch and 600th batchcount\n",
      "[31, 700] loss: 0.140\n",
      "31th epoch and 700th batchcount\n",
      "[31, 800] loss: 0.141\n",
      "31th epoch and 800th batchcount\n",
      "[32, 100] loss: 0.139\n",
      "32th epoch and 100th batchcount\n",
      "[32, 200] loss: 0.140\n",
      "32th epoch and 200th batchcount\n",
      "[32, 300] loss: 0.133\n",
      "32th epoch and 300th batchcount\n",
      "[32, 400] loss: 0.133\n",
      "32th epoch and 400th batchcount\n",
      "[32, 500] loss: 0.147\n",
      "32th epoch and 500th batchcount\n",
      "[32, 600] loss: 0.131\n",
      "32th epoch and 600th batchcount\n",
      "[32, 700] loss: 0.132\n",
      "32th epoch and 700th batchcount\n",
      "[32, 800] loss: 0.130\n",
      "32th epoch and 800th batchcount\n",
      "[33, 100] loss: 0.133\n",
      "33th epoch and 100th batchcount\n",
      "[33, 200] loss: 0.134\n",
      "33th epoch and 200th batchcount\n",
      "[33, 300] loss: 0.130\n",
      "33th epoch and 300th batchcount\n",
      "[33, 400] loss: 0.134\n",
      "33th epoch and 400th batchcount\n",
      "[33, 500] loss: 0.144\n",
      "33th epoch and 500th batchcount\n",
      "[33, 600] loss: 0.141\n",
      "33th epoch and 600th batchcount\n",
      "[33, 700] loss: 0.137\n",
      "33th epoch and 700th batchcount\n",
      "[33, 800] loss: 0.133\n",
      "33th epoch and 800th batchcount\n",
      "[34, 100] loss: 0.142\n",
      "34th epoch and 100th batchcount\n",
      "[34, 200] loss: 0.142\n",
      "34th epoch and 200th batchcount\n",
      "[34, 300] loss: 0.136\n",
      "34th epoch and 300th batchcount\n",
      "[34, 400] loss: 0.131\n",
      "34th epoch and 400th batchcount\n",
      "[34, 500] loss: 0.137\n",
      "34th epoch and 500th batchcount\n",
      "[34, 600] loss: 0.130\n",
      "34th epoch and 600th batchcount\n",
      "[34, 700] loss: 0.138\n",
      "34th epoch and 700th batchcount\n",
      "[34, 800] loss: 0.131\n",
      "34th epoch and 800th batchcount\n",
      "[35, 100] loss: 0.135\n",
      "35th epoch and 100th batchcount\n",
      "[35, 200] loss: 0.136\n",
      "35th epoch and 200th batchcount\n",
      "[35, 300] loss: 0.140\n",
      "35th epoch and 300th batchcount\n",
      "[35, 400] loss: 0.143\n",
      "35th epoch and 400th batchcount\n",
      "[35, 500] loss: 0.125\n",
      "35th epoch and 500th batchcount\n",
      "[35, 600] loss: 0.134\n",
      "35th epoch and 600th batchcount\n",
      "[35, 700] loss: 0.138\n",
      "35th epoch and 700th batchcount\n",
      "[35, 800] loss: 0.135\n",
      "35th epoch and 800th batchcount\n",
      "[36, 100] loss: 0.135\n",
      "36th epoch and 100th batchcount\n",
      "[36, 200] loss: 0.141\n",
      "36th epoch and 200th batchcount\n",
      "[36, 300] loss: 0.128\n",
      "36th epoch and 300th batchcount\n",
      "[36, 400] loss: 0.130\n",
      "36th epoch and 400th batchcount\n",
      "[36, 500] loss: 0.134\n",
      "36th epoch and 500th batchcount\n",
      "[36, 600] loss: 0.150\n",
      "36th epoch and 600th batchcount\n",
      "[36, 700] loss: 0.132\n",
      "36th epoch and 700th batchcount\n",
      "[36, 800] loss: 0.134\n",
      "36th epoch and 800th batchcount\n",
      "[37, 100] loss: 0.145\n",
      "37th epoch and 100th batchcount\n",
      "[37, 200] loss: 0.135\n",
      "37th epoch and 200th batchcount\n",
      "[37, 300] loss: 0.135\n",
      "37th epoch and 300th batchcount\n",
      "[37, 400] loss: 0.136\n",
      "37th epoch and 400th batchcount\n",
      "[37, 500] loss: 0.131\n",
      "37th epoch and 500th batchcount\n",
      "[37, 600] loss: 0.134\n",
      "37th epoch and 600th batchcount\n",
      "[37, 700] loss: 0.138\n",
      "37th epoch and 700th batchcount\n",
      "[37, 800] loss: 0.132\n",
      "37th epoch and 800th batchcount\n",
      "[38, 100] loss: 0.133\n",
      "38th epoch and 100th batchcount\n",
      "[38, 200] loss: 0.138\n",
      "38th epoch and 200th batchcount\n",
      "[38, 300] loss: 0.132\n",
      "38th epoch and 300th batchcount\n",
      "[38, 400] loss: 0.130\n",
      "38th epoch and 400th batchcount\n",
      "[38, 500] loss: 0.139\n",
      "38th epoch and 500th batchcount\n",
      "[38, 600] loss: 0.142\n",
      "38th epoch and 600th batchcount\n",
      "[38, 700] loss: 0.139\n",
      "38th epoch and 700th batchcount\n",
      "[38, 800] loss: 0.132\n",
      "38th epoch and 800th batchcount\n",
      "[39, 100] loss: 0.140\n",
      "39th epoch and 100th batchcount\n",
      "[39, 200] loss: 0.136\n",
      "39th epoch and 200th batchcount\n",
      "[39, 300] loss: 0.129\n",
      "39th epoch and 300th batchcount\n",
      "[39, 400] loss: 0.135\n",
      "39th epoch and 400th batchcount\n",
      "[39, 500] loss: 0.137\n",
      "39th epoch and 500th batchcount\n",
      "[39, 600] loss: 0.134\n",
      "39th epoch and 600th batchcount\n",
      "[39, 700] loss: 0.134\n",
      "39th epoch and 700th batchcount\n",
      "[39, 800] loss: 0.140\n",
      "39th epoch and 800th batchcount\n",
      "[40, 100] loss: 0.131\n",
      "40th epoch and 100th batchcount\n",
      "[40, 200] loss: 0.143\n",
      "40th epoch and 200th batchcount\n",
      "[40, 300] loss: 0.129\n",
      "40th epoch and 300th batchcount\n",
      "[40, 400] loss: 0.143\n",
      "40th epoch and 400th batchcount\n",
      "[40, 500] loss: 0.141\n",
      "40th epoch and 500th batchcount\n",
      "[40, 600] loss: 0.129\n",
      "40th epoch and 600th batchcount\n",
      "[40, 700] loss: 0.133\n",
      "40th epoch and 700th batchcount\n",
      "[40, 800] loss: 0.137\n",
      "40th epoch and 800th batchcount\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40 # 8회가 96%로 제일 높음\n",
    "batchcount = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batchcount = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for features, targets in trainloader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model2(features)\n",
    "\n",
    "        targets = torch.squeeze(targets)\n",
    "        targets = targets.to(torch.float64)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchcount += 1\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batchcount % 100 == 0:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {batchcount}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        if batchcount % 100 == 0:\n",
    "            print(\"%dth epoch and %dth batchcount\" %(epoch + 1, batchcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99da30e6-8631-4b52-b494-42049d8cf1db",
   "metadata": {},
   "source": [
    "## 모델을 검증한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc0126d-87ce-4db1-8c5f-35d3e82320fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataset.TensorDataset'>\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x0000018D22003790>\n"
     ]
    }
   ],
   "source": [
    "testset = TensorDataset(x_testset, y_testset)\n",
    "print(type(testset))\n",
    "print(testset)\n",
    "\n",
    "testbatchsize = 100\n",
    "testloader = DataLoader(testset, batch_size = testbatchsize, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04092edf-4ce4-42ce-b745-0a1483109ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 95 %\n",
      "Precision(PR) : 83 %\n",
      "Sensitivity(SE) : 64 %\n",
      "Specificity(SP) : 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "count = 0\n",
    "\n",
    "TP = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        features, targets = data\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        targets = torch.squeeze(targets)\n",
    "\n",
    "        outputs = model2(features)\n",
    "        for idx, output in enumerate(outputs):\n",
    "            if output[0] >= output[1]: # 예측이 부정\n",
    "                if targets[idx][0] == 1 and targets[idx][1] == 0:\n",
    "                    TN += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "            else: # 예측이 긍정\n",
    "                if targets[idx][0] == 0 and targets[idx][1] == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "print(\"Accuracy : %d %%\" %(100*(TP + TN) / (TP + FN + FP + TN)))\n",
    "print(\"Precision(PR) : %d %%\" %(100*(TP) / (TP + FP)))\n",
    "print(\"Sensitivity(SE) : %d %%\" %(100*(TP) / (TP + FN))) # 현실이 긍정일 때 예측도 긍정일 확률. 높을 수록 긍정 데이터를 잘 표현한다\n",
    "print(\"Specificity(SP) : %d %%\" %(100*(TN) / (FP + TN))) # 현실이 부정일 때 예측도 부정일 확률. 높을 수록 부정 데이터를 잘 표현한다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
